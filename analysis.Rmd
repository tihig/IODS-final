#Analysis

```{r setup, include=FALSE}
library(tidyr); library(plyr); library(dplyr); library(ggplot2)
library(corrplot)
learn<- read.csv("learn.csv")

```

## Introduction

In this final project I will study the data frame learning2014 introduced in the course *Introduction to Open Data Science*, or in short *IODS*. The data frame contains answers from feedback questionnare and exam points from course Introduction to Statistics held in 2014. 

```{r cars, echo=FALSE}
summary(learn)

dim(learn)
```

The data frame has 183 observations and 9 variables. Gender and age are self explanatory variables. Deep, stra and surf refer to the questions asked: deep, strategic and surface questions. Attitude contains scores from questions regarding attitude towards statistics and interest in the same way scores from questions regarding interest towards statistics. Points are the exam points gained by the student. The last variable high_points is a binomial variable containing value true, if the mean score calculated from points and attitude is higher than 26 (mean from all observations).

To study this data frame, I will introduce two hypothesis:

  <span style="color:#159957">*"Students who have on average high exam points and score high on attitude towards statistics also have high interest in statistics."*
  
The first hypothesis suggests that high exam points combined with positive attitude towards statistics indicate that the person is also interested in the field. 

The second hypothesis is the following:

  <span style="color:#159957">*"Students gender does not affect having both high exam points and positive attitude towards statistics."*

In other words, this means that both male and female participants had fairly equal amount of persons with both high exam points and positive attitude answers in poll. In terms of statistics, neither of the genders correlate with high points. These hypothesis will be further examined in the following chapters.


#Looking closer


```{r variables, echo=FALSE}
par(mfrow=c(2,3))

for (i in 1:ncol(learn)) {
  if(colnames(learn)[i] == "high_points"){
    high <- table(learn$high_points)
    barplot(high, main=colnames(learn)[i],  ylab = "Count",col = c("#159957"))
    break
  }else{
  plot(learn[,i], main=colnames(learn)[i],
       ylab = "Count", col = "#159957", las = 2)
  }
}

```

Looking at the variables individually there can be seen some trends in them. Clearly most of the participants are colse to aged 20 and there were more female than men. Attitude and strategic are scattered widely and cannot be further explained here. Most of the students got 15-20 points from their exam. This means that assuming passing required 15 to 18 points, most of the students who answered to the questionnare passed the exam. Interest towards statistics is grouped mostly near 8/10 as is expected (would be quite odd if most of the students of statistics are not interested at all).


```{r versus, echo=FALSE}
par(mfrow=c(2,2))

for (i in 1:ncol(learn)) {
  if(colnames(learn)[i] == "high_points"){
    break
  }else if(colnames(learn)[i] == "attitude" || colnames(learn)[i] == "points" ){
    next
  }

t1 <- table(high_points = learn$high_points, variable = learn[,i])

barplot(t1, main=paste("High points vs", colnames(learn)[i]) ,  ylab = "High Points",col = c("#159957", "#155D93"))
legend("topright", 
       legend = c("F", "T"), 
       fill = c("#159957", "#155D93"), ncol = 2,
       cex = 0.60)

}

```
 
 
The barplots above show the comparison between high points and rest of the variables in data frame. Genderwise, there is a higher proportion of high points in men than in female. It indicates that our hypothesis is false, but let's keep it with us until the correlation is confirmed. 

In interest, ones who answered high in interest (8, 9 or 10) have a higher proportion of high points as well. This is consistent with the hypothesis given above. 


```{r corr, echo=FALSE}
learn_corr <- learn
learn_corr$high_points <- 1 * learn_corr$high_points 
learn_corr$gender <- as.numeric(learn_corr$gender)

cor_matrix<-cor(learn_corr) %>% round(digits= 2)
col1 <- colorRampPalette(c("mediumseagreen","forestgreen","#15866A", "white" ,"#2166AC","#114882", "mediumblue"))

corrplot(cor_matrix, type="upper", cl.pos="b", tl.pos="d", tl.col = "black", tl.cex = 0.6, method="circle", col=col1(100))

```

The correlation matrix above shows that there are no negative correlations in this data frame. On the other hand there is strong positive correlation between interest and attitude. In here the correlation between high points and the rest of the variables is smaller than previously noticed. Still, without a doubt it is significant, since the color and size indicates 0.4 positive correlation.

#Logistic regression

```{r logit, echo=FALSE}
m <- glm(high_points ~ interest + gender, data = learn, family = "binomial")

summary(m)

```

Above is the summary of logistic regression model made for same data frame. The coefficents show that interest is high in statsicial significance. 

For the purpose of testing, let's see how this model would look with surface and age as explanatory variables.

```{r logit2, echo=FALSE}
m2 <- glm(high_points ~ surf + age, data = learn, family = "binomial")

summary(m2)

```

It is clear that this model is far from the explanatory power of the first one. The coefficents correlations scores are unexisting.

It's clear that our hypothesis with gender is proven to be false, so I'll continue with a logistic model without gender.

```{r logit_final, echo=FALSE}
m <- glm(high_points ~ interest, data = learn, family = "binomial")

summary(m)

```



```{r logitgraph, echo=FALSE}
library(popbio)
logi.hist.plot(learn$interest,learn$high_points,boxp=FALSE,type="hist",col="forestgreen")

```

#Odds ratio

```{r odds, echo=FALSE}
OR <- coef(m) %>% exp
CI <- confint(m) %>% exp

cbind(OR, CI)

```
 
The odds ratio of the model tells us that male students are 2,5 times more likely to get high points than female. This brings down our original hypothesis.


#Prediction

To finish off this project, let's see how predicting from this model turns out.
I'll use the Rs own predict- function on the logistic regression model created earlier to count propabilities.

```{r predict, echo=FALSE}
probabilities <- predict(m, type = "response")
learn <- mutate(learn, probability = probabilities)

learn <- mutate(learn, prediction = probabilities > 0.5)
table(high_points = learn$high_points, prediction = probabilities > 0.5)


```


Overall view of the prediction looks successful. The following graph clarifies the prediction with probabilities on the y-axis ( used as basis for making predictions). The probability of having high_points increases when points to interest increases.

```{r curve, echo=FALSE}
m3 <- glm(high_points ~ interest, data = learn, family = "binomial")
plot(learn$interest,learn$probability,xlab="Interest",ylab="Probablity", col="#114882")
curve(predict(m3, data.frame(interest = x), type = "response"),add=TRUE, col="forestgreen") 
points(learn$interest,fitted(m3),pch=20)
```






```{r ggplots, echo=FALSE}




```